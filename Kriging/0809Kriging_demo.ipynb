{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import solve\n",
    "from scipy.optimize import curve_fit\n",
    "from geopy.distance import geodesic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>16.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>5.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>12.8</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site Species ReadingDateTime  Value   Units Provisional or Ratified  \\\n",
       "0  BL0      NO      2018-01-01   16.5  ug m-3                       R   \n",
       "1  BL0      NO      2018-01-02    5.7  ug m-3                       R   \n",
       "2  BL0      NO      2018-01-03   12.8  ug m-3                       R   \n",
       "3  BL0      NO      2018-01-04    9.7  ug m-3                       R   \n",
       "4  BL0      NO      2018-01-05   11.0  ug m-3                       R   \n",
       "\n",
       "         Date   Latitude  Longitude  \n",
       "0  2018-01-01  51.522287  -0.125848  \n",
       "1  2018-01-02  51.522287  -0.125848  \n",
       "2  2018-01-03  51.522287  -0.125848  \n",
       "3  2018-01-04  51.522287  -0.125848  \n",
       "4  2018-01-05  51.522287  -0.125848  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 读取数据\n",
    "camden_no_path = r'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\Camden\\Camden-Nitric Oxide (ug m-3).csv'\n",
    "coords_path = r'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\coords_londonair.csv'\n",
    "meteostat_folder = r'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\meteostat'\n",
    "\n",
    "weighted_no_output_folder = r'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\NO_weighted'\n",
    "\n",
    "camden_no_df = pd.read_csv(camden_no_path)\n",
    "coords_df = pd.read_csv(coords_path)\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "camden_no_df['ReadingDateTime'] = pd.to_datetime(camden_no_df['ReadingDateTime'], format='%d/%m/%Y %H:%M')\n",
    "camden_no_df['Date'] = camden_no_df['ReadingDateTime'].dt.date\n",
    "coords_df[['Latitude', 'Longitude']] = coords_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# 合并坐标信息\n",
    "camden_no_df = pd.merge(camden_no_df, coords_df[['Site', 'Latitude', 'Longitude']], on='Site', how='left')\n",
    "\n",
    "camden_no_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def calculate_distances(coords):\\n    distances = np.zeros((len(coords), len(coords)))\\n    for i, coord1 in enumerate(coords):\\n        for j, coord2 in enumerate(coords):\\n            distances[i, j] = geodesic(coord1, coord2).meters\\n    return distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# calculate_semivariogram 计算半方差函数\n",
    "def calculate_semivariogram(data):\n",
    "    num_points = len(data)\n",
    "    semivariances = []\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            dist = np.linalg.norm([data['Latitude'].iloc[i] - data['Latitude'].iloc[j],\n",
    "                                   data['Longitude'].iloc[i] - data['Longitude'].iloc[j]])\n",
    "            squared_diff = (data['Value'].iloc[i] - data['Value'].iloc[j]) ** 2\n",
    "            semivariances.append((dist, squared_diff))\n",
    "\n",
    "    unique_distances = sorted(set([item[0] for item in semivariances]))\n",
    "    avg_semivariances = []\n",
    "    for dist in unique_distances:\n",
    "        squared_diffs = [item[1] for item in semivariances if item[0] == dist]\n",
    "        avg_semivariances.append((dist, np.mean(squared_diffs) / 2.0))\n",
    "\n",
    "    return np.array(avg_semivariances)\n",
    "\n",
    "# calculate_kriging_weights 计算克里金权重\n",
    "def calculate_kriging_weights(semivariogram, distances, n, nugget=1e-10):\n",
    "    A = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                A[i, j] = semivariogram[0][1] + nugget\n",
    "            else:\n",
    "                dist = int(distances[0, j])\n",
    "                A[i, j] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    A[-1, :-1] = 1\n",
    "    A[:-1, -1] = 1\n",
    "\n",
    "    b = np.zeros(n + 1)\n",
    "    for i in range(n):\n",
    "        dist = int(distances[0, i])\n",
    "        b[i] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    weights = solve(A, b)\n",
    "    return weights[:-1]\n",
    "\n",
    "\n",
    "def adjust_weights(weights, wind_speed, wind_dir, sensor_directions, max_wind_speed):\n",
    "    adjustments = 1 + (wind_speed * np.cos(np.radians(wind_dir - sensor_directions))) / max_wind_speed\n",
    "    adjusted_weights = np.clip(weights * adjustments, 0, None)  # Ensure weights are non-negative\n",
    "    return adjusted_weights\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total_weight = np.sum(weights)\n",
    "    if total_weight == 0:\n",
    "        return np.zeros_like(weights)\n",
    "    return weights / total_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_25904\\1626947359.py:19: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  wind_data_path = f'{meteostat_folder}\\meteostat{year}.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# interpolate 插值估算\n",
    "def interpolate(data, weights):\n",
    "    return np.sum(weights * data['Value'].values)\n",
    "\n",
    "\n",
    "# 修改 get_wind_data 函数\n",
    "def get_wind_data(date, year):\n",
    "    wind_data_path = f'{meteostat_folder}\\meteostat{year}.csv'\n",
    "    wind_data_df = pd.read_csv(wind_data_path, encoding='utf-8-sig')  # 处理BOM\n",
    "    wind_data_df.columns = wind_data_df.columns.str.strip()\n",
    "\n",
    "    # # Debugging: Print column names to verify\n",
    "    # print(\"Column names in wind_data_df:\", wind_data_df.columns)\n",
    "\n",
    "    # 确保日期格式一致\n",
    "    wind_data_df['date'] = pd.to_datetime(wind_data_df['date'], format='%Y-%m-%d').dt.date\n",
    "    date = pd.to_datetime(date, format='%Y-%m-%d').date()  # 确保date参数也被转换成相同格式\n",
    "\n",
    "    wind_info = wind_data_df[wind_data_df['date'] == date]\n",
    "    if not wind_info.empty:\n",
    "        return wind_info['wspd'].values[0], wind_info['wdir'].values[0]\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "\n",
    "def interpolate_and_clip(df, column, method='linear', order=2):\n",
    "    # 获取原始列的最小值和最大值\n",
    "    original_min = df[column].min()\n",
    "    original_max = df[column].max()\n",
    "    \n",
    "    # 进行插值\n",
    "    if method == 'polynomial':\n",
    "        interpolated_values = df[column].interpolate(method=method, order=order)\n",
    "    else:\n",
    "        interpolated_values = df[column].interpolate(method=method)\n",
    "    \n",
    "    # 确保插值后的值在原来值的 {min, max} 范围之间\n",
    "    interpolated_values = interpolated_values.clip(lower=original_min, upper=original_max).round(2)\n",
    "    \n",
    "    # 仅更新空值部分\n",
    "    return df[column].combine_first(interpolated_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 对 \"Value\" 列进行插值并裁剪\n",
    "camden_no_df['Value'] = interpolate_and_clip(camden_no_df, 'Value', method='linear')\n",
    "\n",
    "\"\"\"\n",
    "# Check new CSV\n",
    "camden_no_interpolated_path = camden_no_path.replace('.csv', '_interpolated.csv')\n",
    "camden_no_df.to_csv(camden_no_interpolated_path, index=False)\n",
    "print(f\"Interpolated data saved to {camden_no_interpolated_path}\")\n",
    "camden_no_df.head()\n",
    "\"\"\"\n",
    "\n",
    "# 计算加权空气质量\n",
    "weighted_values = []\n",
    "dates = camden_no_df['Date'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_25904\\3062590836.py:20: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  meteostat_path = f'{meteostat_folder}\\meteostat{date.year}.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\NO_weighted\\Camden-NO_weighted.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure all components of your Kriging process are robust to data issues and correctly implemented.\n",
    "\n",
    "# Adjustments in your main Kriging loop:\n",
    "weighted_values = []\n",
    "dates = camden_no_df['Date'].unique()\n",
    "\n",
    "for date in dates:\n",
    "    daily_data = camden_no_df[camden_no_df['Date'] == date]\n",
    "    if len(daily_data) > 1:\n",
    "        semivariogram = calculate_semivariogram(daily_data)  \n",
    "        # distances = calculate_distances(daily_data[['Latitude', 'Longitude']].values)\n",
    "        distances = cdist(daily_data[['Latitude', 'Longitude']], daily_data[['Latitude', 'Longitude']], metric='euclidean')\n",
    "        # params = fit_semivariogram(daily_data, 10000) # Define an appropriate max_distance\n",
    "        kriging_weights = calculate_kriging_weights(semivariogram, distances, len(daily_data))\n",
    "\n",
    "        wind_speed, wind_dir = get_wind_data(date, date.year)\n",
    "        sensor_directions = np.arctan2(daily_data['Longitude'] - daily_data['Longitude'].mean(), daily_data['Latitude'] - daily_data['Latitude'].mean()) * 180 / np.pi\n",
    "        # max_wind_speed = wind_speed\n",
    "        # 读取对应年份的 meteostat 数据\n",
    "        meteostat_path = f'{meteostat_folder}\\meteostat{date.year}.csv'\n",
    "        meteostat_df = pd.read_csv(meteostat_path)\n",
    "        # 获取该年份中 \"wspd\" 列的最大值\n",
    "        max_wind_speed = meteostat_df['wspd'].max()\n",
    "\n",
    "        adjusted_weights = adjust_weights(kriging_weights, wind_speed, wind_dir, sensor_directions, max_wind_speed)\n",
    "        normalized_weights = normalize_weights(adjusted_weights)\n",
    "\n",
    "        weighted_value = interpolate(daily_data, normalized_weights)\n",
    "        weighted_value = max(0, weighted_value)  # Ensure no negative values\n",
    "        weighted_values.append({'Date': date, 'NO_weighted_value(ug m-3)': weighted_value})\n",
    "    else:\n",
    "        weighted_values.append({'Date': date, 'NO_weighted_value(ug m-3)': daily_data['Value'].values[0]})\n",
    "\n",
    "# Save the weighted values\n",
    "weighted_df = pd.DataFrame(weighted_values)\n",
    "output_path = os.path.join(weighted_no_output_folder, 'Camden-NO_weighted.csv')\n",
    "weighted_df.to_csv(output_path, index=False)\n",
    "print(f\"Weighted data saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
