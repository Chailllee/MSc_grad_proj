{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site                          0\n",
      "Species                       0\n",
      "ReadingDateTime               0\n",
      "Value                      4067\n",
      "Units                         0\n",
      "Provisional or Ratified       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\F'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_9676\\24661811.py:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  camden_no_path = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\Camden\\Camden-Nitric Oxide (ug m-3).csv'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_9676\\24661811.py:3: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  coords_path = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\coords_londonair.csv'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_9676\\24661811.py:4: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  meteostat_folder = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\meteostat\\\\'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 读取数据\n",
    "camden_no_path = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\Camden\\Camden-Nitric Oxide (ug m-3).csv'\n",
    "coords_path = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir\\coords_londonair.csv'\n",
    "meteostat_folder = 'D:\\File_auto\\\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\meteostat\\\\'\n",
    "\n",
    "camden_no_df = pd.read_csv(camden_no_path)\n",
    "coords_df = pd.read_csv(coords_path)\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "camden_no_df['ReadingDateTime'] = pd.to_datetime(camden_no_df['ReadingDateTime'], format='%d/%m/%Y %H:%M')\n",
    "camden_no_df['Date'] = camden_no_df['ReadingDateTime'].dt.date\n",
    "coords_df[['Latitude', 'Longitude']] = coords_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# 合并坐标信息\n",
    "camden_no_df = pd.merge(camden_no_df, coords_df[['Site', 'Latitude', 'Longitude']], on='Site', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 数据预处理\n",
    "camden_no_df['ReadingDateTime'] = pd.to_datetime(camden_no_df['ReadingDateTime'], format='%d/%m/%Y %H:%M')\n",
    "camden_no_df['Date'] = camden_no_df['ReadingDateTime'].dt.date\n",
    "coords_df[['Latitude', 'Longitude']] = coords_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# 合并坐标信息\n",
    "camden_no_df = pd.merge(camden_no_df, coords_df[['Site', 'Latitude', 'Longitude']], on='Site', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 合并坐标信息\n",
    "camden_no_df = pd.merge(camden_no_df, coords_df[['Site', 'Latitude', 'Longitude']], on='Site', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>16.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>5.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>12.8</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site Species ReadingDateTime  Value   Units Provisional or Ratified  \\\n",
       "0  BL0      NO      2018-01-01   16.5  ug m-3                       R   \n",
       "1  BL0      NO      2018-01-02    5.7  ug m-3                       R   \n",
       "2  BL0      NO      2018-01-03   12.8  ug m-3                       R   \n",
       "3  BL0      NO      2018-01-04    9.7  ug m-3                       R   \n",
       "4  BL0      NO      2018-01-05   11.0  ug m-3                       R   \n",
       "\n",
       "         Date   Latitude  Longitude  \n",
       "0  2018-01-01  51.522287  -0.125848  \n",
       "1  2018-01-02  51.522287  -0.125848  \n",
       "2  2018-01-03  51.522287  -0.125848  \n",
       "3  2018-01-04  51.522287  -0.125848  \n",
       "4  2018-01-05  51.522287  -0.125848  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camden_no_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算半方差函数\n",
    "def calculate_semivariogram(data):\n",
    "    num_points = len(data)\n",
    "    semivariances = []\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            dist = np.linalg.norm([data['Latitude'].iloc[i] - data['Latitude'].iloc[j],\n",
    "                                   data['Longitude'].iloc[i] - data['Longitude'].iloc[j]])\n",
    "            squared_diff = (data['Value'].iloc[i] - data['Value'].iloc[j]) ** 2\n",
    "            semivariances.append((dist, squared_diff))\n",
    "\n",
    "    unique_distances = sorted(set([item[0] for item in semivariances]))\n",
    "    avg_semivariances = []\n",
    "    for dist in unique_distances:\n",
    "        squared_diffs = [item[1] for item in semivariances if item[0] == dist]\n",
    "        avg_semivariances.append((dist, np.mean(squared_diffs) / 2.0))\n",
    "\n",
    "    return np.array(avg_semivariances)\n",
    "\n",
    "# 计算克里金权重\n",
    "def calculate_kriging_weights(semivariogram, distances, n, nugget=1e-10):\n",
    "    A = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                A[i, j] = semivariogram[0][1] + nugget\n",
    "            else:\n",
    "                dist = int(distances[0, j])\n",
    "                A[i, j] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    A[-1, :-1] = 1\n",
    "    A[:-1, -1] = 1\n",
    "\n",
    "    b = np.zeros(n + 1)\n",
    "    for i in range(n):\n",
    "        dist = int(distances[0, i])\n",
    "        b[i] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    weights = solve(A, b)\n",
    "    return weights[:-1]\n",
    "\n",
    "# 调整权重\n",
    "def adjust_weights(weights, wind_speed, wind_dir, sensor_directions, max_wind_speed):\n",
    "    adjustments = 1 + (wind_speed * np.cos(np.radians(wind_dir - sensor_directions))) / max_wind_speed\n",
    "    adjusted_weights = weights * adjustments\n",
    "    return adjusted_weights\n",
    "\n",
    "# 归一化调整后的权重\n",
    "def normalize_weights(weights):\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "# 插值估算\n",
    "def interpolate(data, weights):\n",
    "    return np.sum(weights * data['Value'].values)\n",
    "\n",
    "# # 读取风速和风向数据\n",
    "# def get_wind_data(date, year):\n",
    "#     wind_data_path = f'{meteostat_folder}/meteostat{year}.csv'\n",
    "#     # 读取CSV文件并移除BOM\n",
    "#     wind_data_df = pd.read_csv(wind_data_path, encoding='ISO-8859-1')\n",
    "#     wind_data_df.columns = wind_data_df.columns.str.strip()  # 移除列名中的空格\n",
    "#     wind_data_df['date'] = pd.to_datetime(wind_data_df['date'], format='%Y-%m-%d')\n",
    "#     wind_info = wind_data_df[wind_data_df['date'] == pd.to_datetime(date)]\n",
    "#     return wind_info['wspd'].values[0], wind_info['wdir'].values[0]\n",
    "\n",
    "\n",
    "# 修改 get_wind_data 函数\n",
    "def get_wind_data(date, year):\n",
    "    wind_data_path = f'{meteostat_folder}meteostat{year}.csv'\n",
    "    wind_data_df = pd.read_csv(wind_data_path, encoding='utf-8-sig')  # 处理BOM\n",
    "    wind_data_df.columns = wind_data_df.columns.str.strip()\n",
    "\n",
    "    # Debugging: Print column names to verify\n",
    "    print(\"Column names in wind_data_df:\", wind_data_df.columns)\n",
    "\n",
    "    # 确保日期格式一致\n",
    "    wind_data_df['date'] = pd.to_datetime(wind_data_df['date'], format='%Y-%m-%d').dt.date\n",
    "    date = pd.to_datetime(date, format='%Y-%m-%d').date()  # 确保date参数也被转换成相同格式\n",
    "\n",
    "    wind_info = wind_data_df[wind_data_df['date'] == date]\n",
    "    if not wind_info.empty:\n",
    "        return wind_info['wspd'].values[0], wind_info['wdir'].values[0]\n",
    "    else:\n",
    "        return np.nan, np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site                          0\n",
      "Species                       0\n",
      "ReadingDateTime               0\n",
      "Value                      4067\n",
      "Units                         0\n",
      "Provisional or Ratified       0\n",
      "Date                          0\n",
      "Latitude                      0\n",
      "Longitude                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(camden_no_df.isna().sum())\n",
    "# print(wind_data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>16.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>5.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>12.8</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>9.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BL0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>51.522287</td>\n",
       "      <td>-0.125848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site Species ReadingDateTime  Value   Units Provisional or Ratified  \\\n",
       "0  BL0      NO      2018-01-01   16.5  ug m-3                       R   \n",
       "1  BL0      NO      2018-01-02    5.7  ug m-3                       R   \n",
       "2  BL0      NO      2018-01-03   12.8  ug m-3                       R   \n",
       "3  BL0      NO      2018-01-04    9.7  ug m-3                       R   \n",
       "4  BL0      NO      2018-01-05   11.0  ug m-3                       R   \n",
       "\n",
       "         Date   Latitude  Longitude  \n",
       "0  2018-01-01  51.522287  -0.125848  \n",
       "1  2018-01-02  51.522287  -0.125848  \n",
       "2  2018-01-03  51.522287  -0.125848  \n",
       "3  2018-01-04  51.522287  -0.125848  \n",
       "4  2018-01-05  51.522287  -0.125848  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camden_no_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n",
      "Column names in wind_data_df: Index(['date', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt',\n",
      "       'pres', 'tsun'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m semivariogram \u001b[38;5;241m=\u001b[39m calculate_semivariogram(daily_data)\n\u001b[0;32m      9\u001b[0m distances \u001b[38;5;241m=\u001b[39m cdist(daily_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]], daily_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]], metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m kriging_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_kriging_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msemivariogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdaily_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m wind_speed, wind_dir \u001b[38;5;241m=\u001b[39m get_wind_data(date, date\u001b[38;5;241m.\u001b[39myear)\n\u001b[0;32m     13\u001b[0m sensor_directions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marctan2(daily_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m daily_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), daily_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m daily_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m180\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpi\n",
      "Cell \u001b[1;32mIn[14], line 41\u001b[0m, in \u001b[0;36mcalculate_kriging_weights\u001b[1;34m(semivariogram, distances, n, nugget)\u001b[0m\n\u001b[0;32m     38\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(distances[\u001b[38;5;241m0\u001b[39m, i])\n\u001b[0;32m     39\u001b[0m     b[i] \u001b[38;5;241m=\u001b[39m semivariogram[dist][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(semivariogram) \u001b[38;5;28;01melse\u001b[39;00m semivariogram[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 41\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32me:\\Python\\python3.12\\Lib\\site-packages\\scipy\\linalg\\_basic.py:148\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(a, b, lower, overwrite_a, overwrite_b, check_finite, assume_a, transposed)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Flags for 1-D or N-D right-hand side\u001b[39;00m\n\u001b[0;32m    146\u001b[0m b_is_1D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m a1 \u001b[38;5;241m=\u001b[39m atleast_2d(\u001b[43m_asarray_validated\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    149\u001b[0m b1 \u001b[38;5;241m=\u001b[39m atleast_1d(_asarray_validated(b, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite))\n\u001b[0;32m    150\u001b[0m n \u001b[38;5;241m=\u001b[39m a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32me:\\Python\\python3.12\\Lib\\site-packages\\scipy\\_lib\\_util.py:321\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[1;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasked arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    320\u001b[0m toarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray_chkfinite \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray\n\u001b[1;32m--> 321\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32me:\\Python\\python3.12\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# 计算加权空气质量\n",
    "weighted_values = []\n",
    "dates = camden_no_df['Date'].unique()\n",
    "\n",
    "for date in dates:\n",
    "    daily_data = camden_no_df[camden_no_df['Date'] == date]\n",
    "    if len(daily_data) > 1:\n",
    "        semivariogram = calculate_semivariogram(daily_data)\n",
    "        distances = cdist(daily_data[['Latitude', 'Longitude']], daily_data[['Latitude', 'Longitude']], metric='euclidean')\n",
    "        kriging_weights = calculate_kriging_weights(semivariogram, distances, len(daily_data))\n",
    "\n",
    "        wind_speed, wind_dir = get_wind_data(date, date.year)\n",
    "        sensor_directions = np.arctan2(daily_data['Longitude'] - daily_data['Longitude'].mean(), daily_data['Latitude'] - daily_data['Latitude'].mean()) * 180 / np.pi\n",
    "        max_wind_speed = wind_speed\n",
    "\n",
    "        adjusted_weights = adjust_weights(kriging_weights, wind_speed, wind_dir, sensor_directions, max_wind_speed)\n",
    "        normalized_weights = normalize_weights(adjusted_weights)\n",
    "\n",
    "        weighted_value = interpolate(daily_data, normalized_weights)\n",
    "        weighted_values.append({'Date': date, 'NO_weighted_value(ug m-3)': weighted_value})\n",
    "    else:\n",
    "        weighted_values.append({'Date': date, 'NO_weighted_value(ug m-3)': daily_data['Value'].values[0]})\n",
    "\n",
    "# 保存加权后的值\n",
    "weighted_df = pd.DataFrame(weighted_values)\n",
    "weighted_df.to_csv('Camden-NO_weighted.csv', index=False)\n",
    "print(f\"Weighted data saved to Camden-NO_weighted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import solve\n",
    "from math import radians, cos, sin, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "air_data = pd.read_excel('test_air_sensor.xlsx')\n",
    "wind_data = pd.read_csv('wind.csv')\n",
    "\n",
    "\n",
    "# Split the \"Latitude & Longitude\" column into separate columns\n",
    "air_data[['Latitude', 'Longitude']] = air_data['Latitude & Longitude'].str.split(', ', expand=True)\n",
    "air_data['Latitude'] = air_data['Latitude'].astype(float)\n",
    "air_data['Longitude'] = air_data['Longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine formula to calculate distance between two points in meters\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Radius of the Earth in meters\n",
    "    phi1 = radians(lat1)\n",
    "    phi2 = radians(lat2)\n",
    "    delta_phi = radians(lat2 - lat1)\n",
    "    delta_lambda = radians(lon2 - lon1)\n",
    "    a = sin(delta_phi / 2.0) ** 2 + cos(phi1) * cos(phi2) * sin(delta_lambda / 2.0) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    meters = R * c  # Output distance in meters\n",
    "    return meters\n",
    "\n",
    "def calculate_semivariogram(data):\n",
    "    num_points = len(data)  # Number of data points\n",
    "    semivariances = []  # List to store semivariance values\n",
    "\n",
    "    # Nested loop to compare each pair of points\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            # Calculate the distance between point i and point j\n",
    "            dist = haversine(data['Latitude'].iloc[i], data['Longitude'].iloc[i],\n",
    "                             data['Latitude'].iloc[j], data['Longitude'].iloc[j])\n",
    "            # Calculate the squared difference of the NO2 values\n",
    "            squared_diff = (data['NO2(ug m-3)'].iloc[i] - data['NO2(ug m-3)'].iloc[j]) ** 2\n",
    "            # Append the distance and squared difference as a tuple to semivariances\n",
    "            semivariances.append((dist, squared_diff))\n",
    "\n",
    "    # Calculate the average semivariance for each unique distance\n",
    "    unique_distances = sorted(set([item[0] for item in semivariances]))\n",
    "    avg_semivariances = []\n",
    "    for dist in unique_distances:\n",
    "        squared_diffs = [item[1] for item in semivariances if item[0] == dist]\n",
    "        avg_semivariances.append((dist, np.mean(squared_diffs) / 2.0))\n",
    "\n",
    "    # Return the list of (distance, semivariance) tuples as a numpy array\n",
    "    return np.array(avg_semivariances)\n",
    "\n",
    "# # Calculate Kriging weights\n",
    "# def calculate_kriging_weights(semivariogram, distances, n):\n",
    "#     A = np.zeros((n + 1, n + 1))\n",
    "#     A[:n, :n] = semivariogram[distances.astype(int)]\n",
    "#     A[-1, :-1] = 1\n",
    "#     A[:-1, -1] = 1\n",
    "\n",
    "#     b = np.zeros(n + 1)\n",
    "#     b[:-1] = semivariogram[distances.astype(int)]\n",
    "\n",
    "#     weights = solve(A, b)\n",
    "#     return weights[:-1]\n",
    "\n",
    "\n",
    "# def calculate_kriging_weights(semivariogram, distances, n):\n",
    "#     A = np.zeros((n + 1, n + 1))\n",
    "#     for i in range(n):\n",
    "#         for j in range(n):\n",
    "#             A[i, j] = semivariogram[int(distances[i, j])]\n",
    "#     A[-1, :-1] = 1\n",
    "#     A[:-1, -1] = 1\n",
    "\n",
    "#     b = np.zeros(n + 1)\n",
    "#     for i in range(n):\n",
    "#         b[i] = semivariogram[int(distances[i, -1])]\n",
    "\n",
    "#     weights = solve(A, b)\n",
    "#     return weights[:-1]\n",
    "\n",
    "def calculate_kriging_weights(semivariogram, distances, n, nugget=1e-10):\n",
    "    A = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                A[i, j] = semivariogram[0][1] + nugget  # Semivariance at distance 0 with nugget effect\n",
    "            else:\n",
    "                dist = int(distances[0, j])\n",
    "                A[i, j] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]  # Last semivariogram value for large distances\n",
    "\n",
    "    A[-1, :-1] = 1\n",
    "    A[:-1, -1] = 1\n",
    "\n",
    "    b = np.zeros(n + 1)\n",
    "    for i in range(n):\n",
    "        dist = int(distances[0, i])\n",
    "        b[i] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    weights = solve(A, b)\n",
    "    return weights[:-1]\n",
    "\n",
    "# Adjust weights for wind effects\n",
    "def adjust_weights(weights, wind_speed, wind_dir, sensor_directions, avg_wind_speed):\n",
    "    adjustments = 1 + (wind_speed * np.cos(np.radians(wind_dir - sensor_directions))) / avg_wind_speed\n",
    "    adjusted_weights = weights * adjustments\n",
    "    return adjusted_weights\n",
    "\n",
    "# Normalize adjusted weights\n",
    "def normalize_weights(weights):\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "# Perform interpolation\n",
    "def interpolate(data, weights):\n",
    "    return np.sum(weights * data['NO2(ug m-3)'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated NO2 at the interpolation point: 34.39 ug/m3\n"
     ]
    }
   ],
   "source": [
    "# Filter data for the specific date\n",
    "date_filter = '2019-04-01'\n",
    "filtered_air_data = air_data[air_data['Monitor Date'] == date_filter]\n",
    "filtered_wind_data = wind_data[wind_data['date'] == date_filter]\n",
    "\n",
    "# 移除'NO2(ug m-3)'列中的NaN值\n",
    "filtered_air_data = filtered_air_data.dropna(subset=['NO2(ug m-3)'])\n",
    "# 排除'NO2(ug m-3)'列中等于0的行\n",
    "filtered_air_data = filtered_air_data[filtered_air_data['NO2(ug m-3)'] != 0]\n",
    "# 如果'NO2(ug m-3)'列包含字符串类型的空值，也排除这些行（可选）\n",
    "# filtered_air_data = filtered_air_data[filtered_air_data['NO2(ug m-3)'] != '']\n",
    "\n",
    "# Extract wind direction and speed for the specific date\n",
    "wind_speed = filtered_wind_data['wspd'].values[0]\n",
    "wind_dir = filtered_wind_data['wdir'].values[0]\n",
    "\n",
    "# Assume max_distance is 10 (you can change as needed)\n",
    "\n",
    "semivariogram = calculate_semivariogram(filtered_air_data)\n",
    "\n",
    "# Calculate the center point of all sensor locations\n",
    "interpolation_point = np.array([[filtered_air_data['Latitude'].mean(), filtered_air_data['Longitude'].mean()]])\n",
    "# Distances from interpolation point to sensors\n",
    "# distances = cdist(interpolation_point, filtered_air_data[['Latitude', 'Longitude']], metric='euclidean')\n",
    "# Calculate distances from interpolation point to sensors using Haversine formula\n",
    "sensor_locations = filtered_air_data[['Latitude', 'Longitude']].values\n",
    "distances = np.array([[haversine(interpolation_point[0, 0], interpolation_point[0, 1], lat, lon) for lat, lon in sensor_locations]])\n",
    "\n",
    "# Calculate Kriging weights\n",
    "kriging_weights = calculate_kriging_weights(semivariogram, distances, len(filtered_air_data))\n",
    "\n",
    "# Adjust weights for wind effects\n",
    "sensor_directions = np.arctan2(filtered_air_data['Longitude'] - interpolation_point[0, 1], filtered_air_data['Latitude'] - interpolation_point[0, 0]) * 180 / np.pi\n",
    "\n",
    "mean_wind_speed=wind_data['wspd'].mean()\n",
    "adjusted_weights = adjust_weights(kriging_weights, wind_speed, wind_dir, sensor_directions, mean_wind_speed)\n",
    "\n",
    "# Normalize the adjusted weights\n",
    "normalized_weights = normalize_weights(adjusted_weights)\n",
    "\n",
    "# Interpolate to get the estimated air quality\n",
    "estimated_value = interpolate(filtered_air_data, normalized_weights)\n",
    "print(f'Estimated NO2 at the interpolation point: {estimated_value:.2f} ug/m3')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
