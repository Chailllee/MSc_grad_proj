{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import solve\n",
    "from scipy.optimize import curve_fit\n",
    "# from geopy.distance import geodesic\n",
    "from pykrige.ok import OrdinaryKriging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate_semivariogram 计算半方差函数\n",
    "def calculate_semivariogram(data):\n",
    "    num_points = len(data)\n",
    "    semivariances = []\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            dist = np.linalg.norm([data['Latitude'].iloc[i] - data['Latitude'].iloc[j],\n",
    "                                   data['Longitude'].iloc[i] - data['Longitude'].iloc[j]])\n",
    "            squared_diff = (data['Value'].iloc[i] - data['Value'].iloc[j]) ** 2\n",
    "            semivariances.append((dist, squared_diff))\n",
    "\n",
    "    unique_distances = sorted(set([item[0] for item in semivariances]))\n",
    "    avg_semivariances = []\n",
    "    for dist in unique_distances:\n",
    "        squared_diffs = [item[1] for item in semivariances if item[0] == dist]\n",
    "        avg_semivariances.append((dist, np.mean(squared_diffs) / 2.0))\n",
    "\n",
    "    return np.array(avg_semivariances)\n",
    "\n",
    "# calculate_kriging_weights 计算克里金权重\n",
    "def calculate_kriging_weights(semivariogram, distances, n, nugget=1e-10):\n",
    "    A = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                A[i, j] = semivariogram[0][1] + nugget\n",
    "            else:\n",
    "                dist = int(distances[0, j])\n",
    "                A[i, j] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    A[-1, :-1] = 1\n",
    "    A[:-1, -1] = 1\n",
    "\n",
    "    b = np.zeros(n + 1)\n",
    "    for i in range(n):\n",
    "        dist = int(distances[0, i])\n",
    "        b[i] = semivariogram[dist][1] if dist < len(semivariogram) else semivariogram[-1][1]\n",
    "\n",
    "    weights = solve(A, b)\n",
    "    return weights[:-1]\n",
    "\n",
    "\n",
    "def adjust_weights(weights, wind_speed, wind_dir, sensor_directions, max_wind_speed):\n",
    "    adjustments = 1 + (wind_speed * np.cos(np.radians(wind_dir - sensor_directions))) / max_wind_speed\n",
    "    adjusted_weights = np.clip(weights * adjustments, 0, None)  # Ensure weights are non-negative\n",
    "    return adjusted_weights\n",
    "\n",
    "def normalize_weights(weights):\n",
    "    total_weight = np.sum(weights)\n",
    "    if total_weight == 0:\n",
    "        return np.zeros_like(weights)\n",
    "    return weights / total_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\1101129135.py:8: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  wind_data_path = f'{meteostat_folder}\\meteostat{year}.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# interpolate 插值估算\n",
    "def interpolate(data, weights):\n",
    "    return np.sum(weights * data['Value'].values)\n",
    "\n",
    "\n",
    "# 修改 get_wind_data 函数\n",
    "def get_wind_data(date, year):\n",
    "    wind_data_path = f'{meteostat_folder}\\meteostat{year}.csv'\n",
    "    wind_data_df = pd.read_csv(wind_data_path, encoding='utf-8-sig')  # 处理BOM\n",
    "    wind_data_df.columns = wind_data_df.columns.str.strip()\n",
    "\n",
    "    # # Debugging: Print column names to verify\n",
    "    # print(\"Column names in wind_data_df:\", wind_data_df.columns)\n",
    "\n",
    "    # 确保日期格式一致\n",
    "    wind_data_df['date'] = pd.to_datetime(wind_data_df['date'], format='%Y-%m-%d').dt.date\n",
    "    date = pd.to_datetime(date, format='%Y-%m-%d').date()  # 确保date参数也被转换成相同格式\n",
    "\n",
    "    wind_info = wind_data_df[wind_data_df['date'] == date]\n",
    "    if not wind_info.empty:\n",
    "        return wind_info['wspd'].values[0], wind_info['wdir'].values[0]\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "\n",
    "def interpolate_and_clip(df, column, method='linear', order=2):\n",
    "    # 获取原始列的最小值和最大值\n",
    "    original_min = df[column].min()\n",
    "    original_max = df[column].max()\n",
    "    \n",
    "    # 进行插值\n",
    "    if method == 'polynomial':\n",
    "        interpolated_values = df[column].interpolate(method=method, order=order)\n",
    "    else:\n",
    "        interpolated_values = df[column].interpolate(method=method)\n",
    "    \n",
    "    # 确保插值后的值在原来值的 {min, max} 范围之间\n",
    "    interpolated_values = interpolated_values.clip(lower=original_min, upper=original_max).round(2)\n",
    "    \n",
    "    # 仅更新空值部分\n",
    "    return df[column].combine_first(interpolated_values)\n",
    "\n",
    "# 自定义的多项式插值函数\n",
    "def polynomial_interpolation(series, order=2):\n",
    "    return series.interpolate(method='polynomial', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(base_folder, region):\n",
    "    # 构建文件路径\n",
    "    region_folder = os.path.join(base_folder, region)\n",
    "    no_path = os.path.join(region_folder, f'{region}-PM2.5 Particulates (reference equivalent).csv')\n",
    "    coords_path = os.path.join(base_folder, 'coords_sensor.csv')\n",
    "    \n",
    "    # 读取数据\n",
    "    no_df = pd.read_csv(no_path)\n",
    "    coords_df = pd.read_csv(coords_path)\n",
    "    \n",
    "    # 数据预处理\n",
    "    no_df['ReadingDateTime'] = pd.to_datetime(no_df['ReadingDateTime'], format='%d/%m/%Y %H:%M')\n",
    "    no_df['Date'] = no_df['ReadingDateTime'].dt.date\n",
    "    coords_df[['Latitude', 'Longitude']] = coords_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "    \n",
    "    # 合并坐标信息\n",
    "    no_df = pd.merge(no_df, coords_df[['Site', 'Latitude', 'Longitude']], on='Site', how='left')\n",
    "    \n",
    "    # 只处理排在最前面的第一种“Site”的Value值\n",
    "    first_site = no_df['Site'].unique()[0]\n",
    "    no_df = no_df[no_df['Site'] == first_site]\n",
    "    \n",
    "    # 检查并处理 NaN 值\n",
    "    if no_df.isnull().values.any():\n",
    "        print(f\"NaN values found in {region} data before interpolation\")\n",
    "    \n",
    "    # 对于第一个site的任何空缺时间的值，根据其他年份同日期的数据规律进行填充\n",
    "    no_df.set_index('ReadingDateTime', inplace=True)\n",
    "    monthly_daily_mean = no_df.groupby([no_df.index.month, no_df.index.day])['Value'].transform('mean')\n",
    "    no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n",
    "    no_df.reset_index(inplace=True)    # 检查插值结果\n",
    "    if no_df['Value'].isnull().values.any():\n",
    "        print(f\"NaN values found in {region} data after interpolation\")\n",
    "    \n",
    "    return no_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\F'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\2574457806.py:13: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  breathe_folder = 'D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\\\AirQuality\\\\BreatheLondon2'\n"
     ]
    }
   ],
   "source": [
    "# 定义地区列表\n",
    "regions = [\n",
    "    'Camden', 'City of London', 'Islington', \n",
    "    'Kensington and Chelsea', 'Lambeth', \n",
    "    'Southwark', 'Westminster'\n",
    "]\n",
    "\n",
    "# 定义文件夹路径\n",
    "base_folder = r'D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\AirQuality\\LondonAir'\n",
    "meteostat_folder = r'D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\meteostat\\\\'\n",
    "PM25_weighted_output_folder = r'D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\'\n",
    "\n",
    "breathe_folder = 'D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\\\AirQuality\\\\BreatheLondon2'\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "if not os.path.exists(PM25_weighted_output_folder):\n",
    "    os.makedirs(PM25_weighted_output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: Camden\n",
      "NaN values found in Camden data before interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Camden-PM25_weighted.csv\n",
      "Processing region: City of London\n",
      "NaN values found in City of London data before interpolation\n",
      "NaN values found in City of London data after interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\City of London-PM25_weighted.csv\n",
      "Processing region: Islington\n",
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Islington-PM25_weighted.csv\n",
      "Processing region: Kensington and Chelsea\n",
      "NaN values found in Kensington and Chelsea data before interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Kensington and Chelsea-PM25_weighted.csv\n",
      "Processing region: Lambeth\n",
      "NaN values found in Lambeth data before interpolation\n",
      "NaN values found in Lambeth data after interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Lambeth-PM25_weighted.csv\n",
      "Processing region: Southwark\n",
      "NaN values found in Southwark data before interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Southwark-PM25_weighted.csv\n",
      "Processing region: Westminster\n",
      "NaN values found in Westminster data before interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_13544\\3340089105.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  no_df['Value'].fillna(monthly_daily_mean, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted data saved to D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\PM25_weighted\\\\Westminster-PM25_weighted.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 遍历每个地区\n",
    "for region in regions:\n",
    "    print(f\"Processing region: {region}\")\n",
    "    \n",
    "    no_df = preprocess_data(base_folder, region)\n",
    "    # no_df = preprocess_data(base_folder, breathe_folder, region)\n",
    "    \n",
    "    # Kriging 计算\n",
    "    weighted_values = []\n",
    "    dates = no_df['Date'].unique()\n",
    "    \n",
    "    for date in dates:\n",
    "        daily_data = no_df[no_df['Date'] == date]\n",
    "        if len(daily_data) > 1:\n",
    "            semivariogram = calculate_semivariogram(daily_data)\n",
    "            distances = cdist(daily_data[['Latitude', 'Longitude']], daily_data[['Latitude', 'Longitude']], metric='euclidean')\n",
    "            \n",
    "            # 检查并处理 NaN 和 inf 值\n",
    "            if np.isnan(distances).any() or np.isinf(distances).any():\n",
    "                print(f\"NaN or inf values found in distances for {region} on {date}\")\n",
    "                distances = np.nan_to_num(distances, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            \n",
    "            kriging_weights = calculate_kriging_weights(semivariogram, distances, len(daily_data))\n",
    "            \n",
    "            wind_speed, wind_dir = get_wind_data(date, date.year)\n",
    "            sensor_directions = np.arctan2(daily_data['Longitude'] - daily_data['Longitude'].mean(), daily_data['Latitude'] - daily_data['Latitude'].mean()) * 180 / np.pi\n",
    "            meteostat_path = f'{meteostat_folder}\\\\meteostat{date.year}.csv'\n",
    "            meteostat_df = pd.read_csv(meteostat_path)\n",
    "            max_wind_speed = meteostat_df['wspd'].max()\n",
    "            \n",
    "            adjusted_weights = adjust_weights(kriging_weights, wind_speed, wind_dir, sensor_directions, max_wind_speed)\n",
    "            normalized_weights = normalize_weights(adjusted_weights)\n",
    "            \n",
    "            weighted_value = interpolate(daily_data, normalized_weights)\n",
    "            weighted_value = max(0, weighted_value)  # 确保没有负值\n",
    "            weighted_values.append({'Date': date, 'PM25_weighted_value(ug m-3)': weighted_value})\n",
    "        else:\n",
    "            weighted_values.append({'Date': date, 'PM25_weighted_value(ug m-3)': daily_data['Value'].values[0]})\n",
    "    \n",
    "    # 保存加权后的值\n",
    "    weighted_df = pd.DataFrame(weighted_values)\n",
    "    output_path = os.path.join(PM25_weighted_output_folder, f'{region}-PM25_weighted.csv')\n",
    "    weighted_df.to_csv(output_path, index=False)\n",
    "    print(f\"Weighted data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
