{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "data1_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\NO_weighted\"\n",
    "data2_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\dfl_traffic_count\"\n",
    "data3_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\tfl_crowding_data\"\n",
    "\n",
    "# Function to read CSV files containing \"Camden\" in their names\n",
    "def read_camden_csvs(folder_path):\n",
    "    camden_dfs = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and 'Camden' in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                camden_dfs.append(df)\n",
    "    return camden_dfs\n",
    "\n",
    "# Read data1 and data2\n",
    "data1_dfs = read_camden_csvs(data1_path)\n",
    "data2_dfs = read_camden_csvs(data2_path)\n",
    "\n",
    "# Merge data1 and data2 on 'Date' and 'count_data'\n",
    "merged_data1_data2 = pd.DataFrame()\n",
    "for df1 in data1_dfs:\n",
    "    for df2 in data2_dfs:\n",
    "        merged_df = pd.merge(df1, df2, left_on='Date', right_on='count_data', how='left')\n",
    "        merged_data1_data2 = pd.concat([merged_data1_data2, merged_df], ignore_index=True)\n",
    "\n",
    "# Read data3 and filter by 'Borough' == 'Camden'\n",
    "data3_dfs = []\n",
    "for year in range(2019, 2025):\n",
    "    file_name = f\"filtered_StationFootfall_{year}_merged.csv\"\n",
    "    file_path = os.path.join(data3_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        camden_df = df[df['Borough'] == 'Camden']\n",
    "        data3_dfs.append(camden_df)\n",
    "\n",
    "# Merge data3 with merged_data1_data2 on 'TravelDate'\n",
    "final_merged_data = merged_data1_data2.copy()\n",
    "for df3 in data3_dfs:\n",
    "    final_merged_data = pd.merge(final_merged_data, df3, left_on='Date', right_on='TravelDate', how='left')\n",
    "\n",
    "# Save the final merged data to a CSV file\n",
    "output_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\Correlation\\corr_merged.csv\"\n",
    "final_merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Data merged and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
