{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data1_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\"\n",
    "data2_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\dfl_traffic_count\"\n",
    "data3_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data\\tfl_crowding_data\"\n",
    "\n",
    "regions = ['Camden', 'City of London', 'Islington', 'Kensington and Chelsea', 'Lambeth', 'Southwark', 'Westminster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Camden merged and saved successfully.\n",
      "Data for City of London merged and saved successfully.\n",
      "Data for Islington merged and saved successfully.\n",
      "Data for Kensington and Chelsea merged and saved successfully.\n",
      "Data for Lambeth merged and saved successfully.\n",
      "Data for Southwark merged and saved successfully.\n",
      "Data for Westminster merged and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to read CSV files containing region name in their names and merge them based on 'Date'\n",
    "def read_and_merge_data1(folder_path, region):\n",
    "    subfolders = [\"NO_weighted\", \"NO2_weighted\", \"PM10_weighted\", \"PM25_weighted\"]\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        for root, dirs, files in os.walk(subfolder_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv') and region in file:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    air_type = subfolder.split('_')[0]\n",
    "                    df.rename(columns={f\"{air_type}_weighted_value(ug m-3)\": f\"{air_type}_value\"}, inplace=True)\n",
    "                    df['Date'] = df['Date'].str.strip()  # Remove leading/trailing spaces\n",
    "                    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')  # Handle invalid dates\n",
    "                    if merged_df.empty:\n",
    "                        merged_df = df\n",
    "                    else:\n",
    "                        merged_df = pd.merge(merged_df, df[['Date', f\"{air_type}_value\"]], on='Date', how='outer')\n",
    "    return merged_df\n",
    "\n",
    "# Function to read CSV files containing region name in their names from data2 and merge with data1\n",
    "def read_and_merge_data2(data1_df, folder_path, region):\n",
    "    columns_of_interest = [\n",
    "        'pedal_cycles', 'two_wheeled_motor_vehicles', 'cars_and_taxis', 'buses_and_coaches', 'lgvs',\n",
    "        'hgvs_2_rigid_axle', 'hgvs_3_rigid_axle', 'hgvs_4_or_more_rigid_axle', 'hgvs_3_or_4_articulated_axle',\n",
    "        'hgvs_5_articulated_axle', 'hgvs_6_articulated_axle'\n",
    "    ]\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and region in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['count_date'] = df['count_date'].str.strip()  # Remove leading/trailing spaces\n",
    "                df['Date'] = pd.to_datetime(df['count_date'], format='%Y/%m/%d', errors='coerce')  # Handle invalid dates\n",
    "                df_major = df[df['road_type'] == 'Major'][['Date'] + columns_of_interest].add_suffix('_major')\n",
    "                df_minor = df[df['road_type'] == 'Minor'][['Date'] + columns_of_interest].add_suffix('_minor')\n",
    "                df_major.rename(columns={'Date_major': 'Date'}, inplace=True)\n",
    "                df_minor.rename(columns={'Date_minor': 'Date'}, inplace=True)\n",
    "                data1_df = pd.merge(data1_df, df_major, on='Date', how='left')\n",
    "                data1_df = pd.merge(data1_df, df_minor, on='Date', how='left')\n",
    "    return data1_df\n",
    "\n",
    "# Function to read CSV files from data3, filter by 'Borough' == region, and merge with data1\n",
    "def read_and_merge_data3(data1_df, folder_path, region):\n",
    "    all_years_df = pd.DataFrame()\n",
    "    for year in range(2019, 2025):\n",
    "        file_name = f\"filtered_StationFootfall_{year}_merged.csv\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df[df['Borough'] == region]\n",
    "            try:\n",
    "                df['TravelDate'] = df['TravelDate'].astype(str).str.strip()  # Remove leading/trailing spaces\n",
    "                df['TravelDate'] = pd.to_datetime(df['TravelDate'], format='%Y%m%d', errors='coerce')  # Handle invalid dates\n",
    "            except ValueError:\n",
    "                df['TravelDate'] = pd.to_datetime(df['TravelDate'], errors='coerce')\n",
    "            df = df[['TravelDate', 'EntryTapCount', 'ExitTapCount']]\n",
    "            all_years_df = pd.concat([all_years_df, df])\n",
    "    all_years_df = all_years_df.groupby('TravelDate').sum().reset_index()\n",
    "    data1_df = pd.merge(data1_df, all_years_df, left_on='Date', right_on='TravelDate', how='left')\n",
    "    data1_df.drop(columns=['TravelDate'], inplace=True)\n",
    "    return data1_df\n",
    "\n",
    "\n",
    "# Process each region and save the merged data\n",
    "for region in regions:\n",
    "    data1_merged = read_and_merge_data1(data1_path, region)\n",
    "    data1_merged = read_and_merge_data2(data1_merged, data2_path, region)\n",
    "    final_merged_data = read_and_merge_data3(data1_merged, data3_path, region)\n",
    "    \n",
    "    output_path = f\"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data_output\\\\Correlation\\\\{region}_corr_merged.csv\"\n",
    "    final_merged_data.to_csv(output_path, index=False)\n",
    "    print(f\"Data for {region} merged and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all regions merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All regions data merged and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all region files into one final file\n",
    "all_regions_df = pd.DataFrame()\n",
    "for region in regions:\n",
    "    file_path = f\"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data_output\\\\Correlation\\\\{region}_corr_merged.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Region'] = region\n",
    "        all_regions_df = pd.concat([all_regions_df, df])\n",
    "\n",
    "final_output_path = r\"D:\\File_auto\\0_UCL_CASA\\OneDrive - University College London\\Xiaoyi_dissertation\\Analysis\\Data_output\\Correlation\\corr_merged.csv\"\n",
    "all_regions_df.to_csv(final_output_path, index=False)\n",
    "\n",
    "print(\"All regions data merged and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
