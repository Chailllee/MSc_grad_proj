{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 定义区域和时间点\n",
    "regions = ['Camden', 'City of London', 'Islington', 'Kensington and Chelsea', 'Lambeth', 'Southwark', 'Westminster']\n",
    "\n",
    "# Ensure time_points only contain dates (not times)\n",
    "time_points = {\n",
    "    \"2019 Central Zone\": pd.to_datetime(\"2019-04-08\").date(),\n",
    "    \"2020 Covid-19 Lockdown\": pd.to_datetime(\"2020-01-01\").date(),\n",
    "    \"2021 Lockdown release\": pd.to_datetime(\"2021-02-22\").date(),\n",
    "    \"2021 Inner Expansion\": pd.to_datetime(\"2021-10-25\").date(),\n",
    "    \"2023 Outer Expansion\": pd.to_datetime(\"2023-08-29\").date()\n",
    "}\n",
    "\n",
    "# Adjust time_periods to match the date-only format\n",
    "# Ensure time_periods contains datetime.date objects\n",
    "time_periods = {\n",
    "    \"pre2019ULEZ\": (pd.to_datetime(\"2015-01-01\").date(), pd.to_datetime(\"2019-04-07\").date()),\n",
    "    \"post2019ULEZ_pre2021ULEZ\": (pd.to_datetime(\"2019-04-08\").date(), pd.to_datetime(\"2021-10-24\").date()),\n",
    "    \"post2021ULEZ_pre2023ULEZ\": (pd.to_datetime(\"2021-10-25\").date(), pd.to_datetime(\"2023-08-28\").date()),\n",
    "    # \"post2023ULEZ\": (pd.to_datetime(\"2023-08-29\").date(), None)\n",
    "    \"post2023ULEZ\": (pd.to_datetime(\"2023-08-29\").date(), pd.to_datetime(\"2024-08-29\").date())\n",
    "}\n",
    "\n",
    "# 读取传感器坐标数据\n",
    "coords_path = \"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data\\\\AirQuality\\\\LondonAir\\\\coords_sensor.csv\"\n",
    "coords_df = pd.read_csv(coords_path)\n",
    "# coords_df[['Latitude', 'Longitude']] = coords_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# 定义气体种类\n",
    "species_files = {\n",
    "    \"NO\": \"Nitric Oxide (ug m-3).csv\",\n",
    "    \"NO2\": \"Nitrogen Dioxide (ug m-3).csv\",\n",
    "    \"PM2.5\": \"PM2.5 Particulates (reference equivalent).csv\",\n",
    "    \"PM10\": \"PM10 Particulates (reference equivalent).csv\"\n",
    "}\n",
    "\n",
    "# 创建结果数据框\n",
    "results = {species: [] for species in species_files.keys()}\n",
    "\n",
    "\n",
    "breathe_folder=\"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data\\\\AirQuality\\\\BreatheLondon2\\\\\"\n",
    "output_dir =\"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data_output\\\\Difference\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 遍历每个区域和气体种类\n",
    "for region in regions:\n",
    "    for species, file_suffix in species_files.items():\n",
    "        file_path = f\"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data\\\\AirQuality\\\\LondonAir\\\\{region}\\\\{region}-{file_suffix}\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 转换日期时间格式并去掉时间部分\n",
    "        df[\"ReadingDateTime\"] = pd.to_datetime(df[\"ReadingDateTime\"], format=\"%d/%m/%Y %H:%M\").dt.date\n",
    "        \n",
    "\n",
    "\n",
    "        # # 检查2021年之后的数据是否有缺失\n",
    "        if df[df[\"ReadingDateTime\"] > pd.to_datetime('2021-01-27').date()]['Value'].isnull().values.any():\n",
    "            breathe_region_folder = os.path.join(breathe_folder, region)  # 替换为实际BreatheLondon2数据文件夹路径\n",
    "            breathe_files = [f for f in os.listdir(breathe_region_folder) if f.endswith(f'_{species}.csv')]\n",
    "            \n",
    "            for file in breathe_files:\n",
    "                try:\n",
    "                    breathe_df = pd.read_csv(os.path.join(breathe_region_folder, file))\n",
    "                    \n",
    "                    # 统一日期格式\n",
    "                    breathe_df['ReadingDateTime'] = pd.to_datetime(breathe_df['Date'], format='%Y-%m-%d').dt.date\n",
    "                    breathe_df.rename(columns={f'{species}_mean': 'Value'}, inplace=True)\n",
    "                    \n",
    "                    # 提取坐标信息\n",
    "                    coords_breathe_df = pd.read_csv(coords_path)\n",
    "                    # coords_breathe_df[['Latitude', 'Longitude']] = coords_breathe_df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "\n",
    "                    # 从文件名提取站点信息并添加到数据框\n",
    "                    site_name = file.replace(f' - {species}.csv', '')\n",
    "                    breathe_df['Site'] = site_name\n",
    "\n",
    "\n",
    "                    # 添加缺失的列\n",
    "                    breathe_df['Species'] = species\n",
    "                    breathe_df['Units'] = 'Unknown'  # 或者使用适当的默认值\n",
    "                    breathe_df['Provisional or Ratified'] = 'Unknown'  # 或者使用适当的默认值\n",
    "                    \n",
    "                    # 选择并重新排列列以匹配 df\n",
    "                    breathe_df = breathe_df[['Site', 'Species', 'ReadingDateTime', 'Value', 'Units', 'Provisional or Ratified']]\n",
    "                    # breathe_df = breathe_df[['Site', 'Species', 'ReadingDateTime', 'Value', 'Units', 'Provisional or Ratified', 'Latitude & Longitude']]\n",
    "\n",
    "                    # 合并数据\n",
    "                    df = pd.concat([df, breathe_df], ignore_index=True)\n",
    "\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing file {file}: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error processing file {file}: {e}\")\n",
    "\n",
    "        # 计算每个时间段的平均值\n",
    "        mean_values = {}\n",
    "        for period, (start, end) in time_periods.items():\n",
    "            if isinstance(start, list):  # 处理多个时间段\n",
    "                period_df = pd.concat([df[(df[\"ReadingDateTime\"] > s) & (df[\"ReadingDateTime\"] <= e)] for s, e in start])\n",
    "            else:\n",
    "                period_df = df[(df[\"ReadingDateTime\"] > start) & (df[\"ReadingDateTime\"] <= end)] if start else df[df[\"ReadingDateTime\"] <= end]\n",
    "            mean_values[period] = period_df[\"Value\"].mean()\n",
    "\n",
    "\n",
    "        df_mean = pd.DataFrame(mean_values, index=[0])\n",
    "        df_mean.to_csv(os.path.join(output_dir,f\"{species}_meanvalue.csv\"), index=False)# 检查post2023ULEZ的值是否为NaN\n",
    "        # if pd.isna(mean_values[\"post2023ULEZ\"]):\n",
    "        #     print(f\"Warning: Mean value for post2023ULEZ is NaN for region {region} and species {species}\")\n",
    "\n",
    "        # 计算百分比变化\n",
    "        percentage_changes = {\n",
    "            \"post2019\": (mean_values[\"post2019ULEZ_pre2021ULEZ\"] - mean_values[\"pre2019ULEZ\"]) * 100 / mean_values[\"pre2019ULEZ\"],\n",
    "            \"post2021\": (mean_values[\"post2021ULEZ_pre2023ULEZ\"] - mean_values[\"pre2019ULEZ\"]) * 100 / mean_values[\"pre2019ULEZ\"],\n",
    "            \"post2023\": (mean_values[\"post2023ULEZ\"] - mean_values[\"pre2019ULEZ\"]) * 100 / mean_values[\"pre2019ULEZ\"]\n",
    "        }\n",
    "        \n",
    "        # 获取传感器信息\n",
    "        sensor_info = coords_df[coords_df[\"Site\"].isin(df[\"Site\"].unique())]\n",
    "        \n",
    "        # 生成结果数据\n",
    "        for period, change in percentage_changes.items():\n",
    "            for site in sensor_info[\"Site\"].unique():\n",
    "\n",
    "                # 打印调试信息\n",
    "                # print(f\"Processing site: {site} for period: {period}\")\n",
    "\n",
    "                site_info = sensor_info[sensor_info[\"Site\"] == site].iloc[0]\n",
    "\n",
    "                results[species].append({\n",
    "                    \"Site\": site,\n",
    "                    \"ULEZ_period\": period,\n",
    "                    \"Percentage_Change\": change,\n",
    "                    \"Mean_Value\": mean_values.get(f\"post{period.split('post')[1]}ULEZ_pre2021ULEZ\", None),\n",
    "                    \"Classification\": site_info[\"Classification\"],\n",
    "                    \"Latitude & Longitude\": site_info[\"Latitude & Longitude\"]\n",
    "                })\n",
    "\n",
    "# 保存结果到CSV文件\n",
    "output_dir = \"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data_output\\\\Difference\\\\\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for species, data in results.items():\n",
    "    output_path = os.path.join(output_dir, f\"{species}_diff.csv\")\n",
    "    pd.DataFrame(data).to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\1184608704.py:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  lon_msoa = gpd.read_file('D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data\\london_boundaries\\statistical-gis-boundaries-london\\statistical-gis-boundaries-london\\ESRI\\MSOA_2011_London_gen_MHW.shp')\n"
     ]
    }
   ],
   "source": [
    "# 读取Shapefile文件\n",
    "lon_msoa = gpd.read_file('D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data\\london_boundaries\\statistical-gis-boundaries-london\\statistical-gis-boundaries-london\\ESRI\\MSOA_2011_London_gen_MHW.shp')\n",
    "\n",
    "# 筛选指定的boroughs\n",
    "selected_boroughs = lon_msoa[lon_msoa['LAD11NM'].isin(['City of London', 'Islington', 'Kensington and Chelsea', 'Westminster', 'Camden', 'Lambeth', 'Southwark'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_boroughs.head()\n",
    "print(selected_boroughs.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义输出目录和物种列表\n",
    "output_dir = \"D:\\\\File_auto\\\\0_UCL_CASA\\\\OneDrive - University College London\\\\Xiaoyi_dissertation\\\\Analysis\\\\Data_output\\\\Difference\\\\\"\n",
    "species_list = [\"NO\", \"NO2\", \"PM2.5\", \"PM10\"]  # 替换为实际物种列表\n",
    "ulez_periods = [\"post2019\", \"post2021\", \"post2023\"]  # 替换为实际ULEZ时期列表\n",
    "\n",
    "# 定义物种全称\n",
    "species_full_names = {\n",
    "    \"NO\": \"Nitric Oxide (NO)\",\n",
    "    \"NO2\": \"Nitrogen Dioxide (NO2)\",\n",
    "    \"PM10\": \"PM10\",\n",
    "    \"PM2.5\": \"PM2.5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
      "C:\\Users\\Chailee\\AppData\\Local\\Temp\\ipykernel_14440\\2253033625.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n"
     ]
    }
   ],
   "source": [
    "# 遍历每个物种和每个ULEZ时期\n",
    "for species in species_list:\n",
    "    csv_file = os.path.join(output_dir, f\"{species}_diff.csv\")\n",
    "    if os.path.exists(csv_file):\n",
    "        # 读取CSV文件\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # 去掉“Latitude & Longitude”列中的引号\n",
    "        df['Latitude & Longitude'] = df['Latitude & Longitude'].str.replace('\"', '')\n",
    "        \n",
    "        # 分割“Latitude & Longitude”列\n",
    "        df[['Latitude', 'Longitude']] = df['Latitude & Longitude'].str.split(', ', expand=True).astype(float)\n",
    "        \n",
    "        for period in ulez_periods:\n",
    "            # 根据ULEZ_period过滤数据\n",
    "            period_df = df[df['ULEZ_period'] == period]\n",
    "            \n",
    "            # 转换为GeoDataFrame\n",
    "            geometry = [Point(xy) for xy in zip(period_df['Longitude'], period_df['Latitude'])]\n",
    "            gdf = gpd.GeoDataFrame(period_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "            \n",
    "            # 将GeoDataFrame的坐标系从WGS84转换为OSGB36\n",
    "            gdf = gdf.to_crs(\"EPSG:27700\")\n",
    "            \n",
    "            # 绘制图像\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "            selected_boroughs.boundary.plot(ax=ax, edgecolor='black')  # 只显示轮廓\n",
    "            cmap = plt.cm.get_cmap('viridis_r')  # 反转颜色映射\n",
    "            gdf.plot(ax=ax, markersize=gdf['Percentage_Change'].abs() * 10, c=gdf['Percentage_Change'], cmap=cmap, legend=True)\n",
    "            \n",
    "            # 设置标题\n",
    "            plt.title(f\"Post {period[-4:]} ULEZ Percentage Change for {species_full_names[species]}\")\n",
    "            \n",
    "            # 保存图像\n",
    "            plt.savefig(f\"Post_{period[-4:]}_ULEZ_Percentage_Change_for_{species_full_names[species].replace(' ', '_').replace('(', '').replace(')', '')}.png\")\n",
    "            plt.close(fig)\n",
    "    else:\n",
    "        print(f\"File {csv_file} does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
